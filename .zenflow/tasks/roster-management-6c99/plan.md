# New feature


## Configuration
- **Artifacts Path**: `.zenflow/tasks/{task_id}`
the actual path should be substituted for {@artifacts_path}

---

## Workflow Steps

### [x] Step: Requirements
<!-- chat-id: 6464ca7c-5f05-4164-9ac1-468ca7529031 -->

Your job is to generate a Product Requirements Document based on the feature description,

First, analyze the provided feature definition and determine unclear aspects.  For unclear aspects:
       - Make informed guesses based on context and industry standards
       - Only mark with [NEEDS CLARIFICATION: specific question] if:
         - The choice significantly impacts feature scope or user experience
         - Multiple reasonable interpretations exist with different implications
         - No reasonable default exists
      - Prioritize clarifications by impact: scope > security/privacy > user experience > technical details

Ask up to 5 most priority clarifications to the user. Then, create the document following this template:

```
# Feature Specification: [FEATURE NAME]


## User Stories*


### User Story 1 - [Brief Title]

**Acceptance Scenarios**:

1. **Given** [initial state], **When** [action], **Then** [expected outcome]
2. **Given** [initial state], **When** [action], **Then** [expected outcome]

---

## Requirements*

## Success Criteria*

```

Save the PRD into `{@artifacts_path}/requirements.md`.

### [x] Step: Technical Specification
<!-- chat-id: c40a9d57-f70b-4a91-a969-573b5de0d73d -->

Based on the PRD in `{@artifacts_path}/requirements.md`, create a detailed technical specification to be used by a coding agent to implement the feature. Follow this template:

```
# Technical Specification: [FEATURE]

## Technical Context
Language/Version, primary dependencies, etc

## Technical Implementation Brief

Summarize key technical decisions for implementing the feature. Make sure they take into account the existing code as much as possible.

## Source Code Structure

## Contracts

Define addition or changes in data models, DB schemas, APIs, code interfaces etc

## Delivery Phases

Define several incremental deliverables for the feature. Each should be a minimal viable product testable end-to-end.

## Verification Strategy 

Define how the coding agent can verify each deliverable it creates. Provide instructions for the agent to perform the verification using available tools (lint/test commands, bash commands) and create helper scripts and tools for more complex result verification.
The verification for each deliverable should be executable by a coding agent using built-in capabilities (lint and test commands from the project, bash commands), pre-generated helper scripts or MCP servers. Research and add to the spec:

- MCP servers that should be installed to help the agent with the verification 

- helper scripts that need to be generated in the first phases of the plan to verify complex scenarios that can't be covered by the tests in the project's test framework(s)

- any sample input artifact(s) that are required for verification. Note if these artifacts can be a) generated by the agent; b) discovered by the agent on line; c) must be provided by the user.
```

Save the spec to `{@artifacts_path}/spec.md`.

### [x] Step: Implementation Plan
<!-- chat-id: 753d82c4-812a-4cc7-ab5c-2a3d09db1d2e -->

Based on the technical spec in `{@artifacts_path}/spec.md`, create a detailed task plan and update `{@artifacts_path}/plan.md`. Each task should have task definition, references to contracts to be used/implemented, deliverable definition and verification instructions.

Format each task as 
```
### [ ] Step: <task_name>
Task instructions
```

"Step:" prefix is important, do not omit it!

### [x] Step: Add Year Context State & Contracts
<!-- chat-id: 1230bf8e-3800-4b35-8977-25817bd17ec1 -->
Task definition
- Introduce per-team year context state and public accessors in `docs/roster_cap_tool/js/state.js`.
- Backward compatible default `Y+0` when absent; do not change existing behavior until UI wiring.

Contracts (from spec)
- Add `state.yearContextByTeam: { [abbr: string]: number }` (offset in years, default 0).
- Add functions: `getYearContextForSelectedTeam(): number`, `setYearContextForSelectedTeam(offset:number): void`, `getContextLabel(): string`.
- Extend Scenario object model to support `yearContextOffset?: number` (optional, default 0) in `docs/roster_cap_tool/js/models.js` JSDoc.

Deliverable
- State accessors exported and no-op by default; existing E2E stay green.

Verification
- Run `npm run test:e2e` to confirm no regressions.
- Manual: load app; ensure no UI/behavior changes yet and no console errors.

### [x] Step: Create Context Helpers Module
<!-- chat-id: b918d5e1-fbe7-447f-8700-5e538014d08d -->
Task definition
- Add `docs/roster_cap_tool/js/context.js` with pure helpers to compute contextual player and roster views for a given offset, without mutating inputs.

Contracts (from spec)
- Export: `contextualizePlayer(player, team, offset)`, `contextualizeRoster(players, team, offset)`, `getContextualPlayers()` (wrapper using state).
- Derived fields (suffix `_ctx` only on returned objects): `contractYearsLeft_ctx`, `isFreeAgent_ctx`, `capHit_ctx`, `capReleasePenalty_ctx`, `capReleaseNetSavings_ctx`.
- Use proration logic and base schedule per spec.

Deliverable
- New module loads successfully and exports functions; not yet wired to UI/state getters.

Verification
- Node import smoke: `node -e "import('file://$PWD/docs/roster_cap_tool/js/context.js').then(()=>console.log('ok'))"` prints ok.
- E2E unaffected: `npm run test:e2e`.

### [x] Step: Wire Roster Getters To Context
<!-- chat-id: 675f60e6-9165-4e6a-adf5-c319171cd96b -->
Task definition
- Update `getActiveRoster()` and `getFreeAgents()` in `docs/roster_cap_tool/js/state.js` to return contextualized players when year context offset > 0.
- Ensure default behavior (`offset=0`) matches existing results bit-for-bit.

Contracts (from spec)
- `getContextualPlayers()` used internally by getters when `getYearContextForSelectedTeam() > 0`.
- `isFreeAgent_ctx` determines membership in Active vs Free Agents for context > 0.

Deliverable
- Derived getters return contextual data behind the same API signature; no visual change until UI can switch offset.

Verification
- `npm run test:e2e` should still pass with default Y+0.
- Manual: add a temporary `console.debug` of counts under `offset=1` toggle via devtools to sanity-check (remove before commit).

### [ ] Step: Add Context Cap Summary
Task definition
- Implement `calcCapSummaryForContext(team, players, moves, contextOffset, opts)` per spec in `docs/roster_cap_tool/js/capMath.js` and export it.
- Update `getCapSummary()` in `docs/roster_cap_tool/js/state.js` to call context-aware version when `offset>0`.

Contracts (from spec)
- Use `projectTeamCaps(team, players, moves, horizon, opts)` and read snapshot/baseline at index `contextOffset`.
- Return `{ capRoom, capSpent, capAvailable, deadMoney, baselineAvailable, deltaAvailable }`.

Deliverable
- Accurate cap summary in context; default path unchanged for `offset=0`.

Verification
- `npm run test:e2e` to confirm no regressions in smoke/projections.
- Later tied to unit tests in `scripts/test_year_context.mjs` (added in a subsequent step).

### [ ] Step: Year Context UI Control
Task definition
- Add a new UI module `docs/roster_cap_tool/js/ui/yearContext.js` that renders a small selector (Y+0, Y+1, Y+2, Y+3...) and updates state.
- Insert container `<div id="year-context"></div>` into `docs/roster_cap_tool/index.html` header (right side), next to the team selector.
- Wire `mountYearContext()` calls in `docs/roster_cap_tool/js/main.js` alongside other mounts and on state subscription.

Contracts (from spec)
- Container: `#year-context`.
- Buttons testids: `data-testid="year-context-0"`, `year-context-1`, `year-context-2`, …
- Label helper: `data-testid="year-context-label"` displays `Y+N`.

Deliverable
- Visible year context control with default Y+0 selected; clicking updates state and triggers re-render.

Verification
- Manual: switch Y+0 → Y+1 and observe roster counts/cap summary change sensibly.
- E2E will cover in a later step; interim smoke via `npm run test:e2e` should remain green.

### [ ] Step: Update Column Headers For Context
Task definition
- Update roster table cap column label to include the current context (e.g., `Cap (Y+1)`) and add test id.

Contracts (from spec)
- In `docs/roster_cap_tool/js/ui/playerTable.js`, set header label with `data-testid="col-cap-label"` using `getContextLabel()`.

Deliverable
- Header text reflects selected year context across tables where applicable.

Verification
- Manual: switch context and confirm header updates.
- New E2E will assert via `col-cap-label`.

### [ ] Step: Context-Aware Actions (Release/Trade/Extend/Convert/Sign)
Task definition
- Ensure simulation helpers and modals use contextual player view and cap snapshot for the selected year.
- Update modal previews to reflect penalties/savings in the context year.

Contracts (from spec)
- Modals under `docs/roster_cap_tool/js/ui/modals/*.js` should fetch players through contextual getters and use `getCapSummary()` (which is context-aware now).
- Keep existing move encoding format; only calculations adapt to context.

Deliverable
- Releasing/trading/extending/etc while in Y+1/Y+2 shows correct penalties/savings and updates the cap summary consistently.

Verification
- Manual: try a release in Y+1 and compare against expected savings using proration rules.
- E2E in a later step will automate checks.

### [ ] Step: Scenario Persistence For Context
Task definition
- Include `yearContextOffset` in scenario save/load routines and ensure Reset behavior does not reset the context per PRD.

Contracts (from spec)
- Update scenario JSDoc in `docs/roster_cap_tool/js/models.js` and scenario helpers in `docs/roster_cap_tool/js/ui/scenarioControls.js`/modals to persist `yearContextOffset`.

Deliverable
- Saving and loading a scenario restores the selected context value; Reset keeps current context.

Verification
- Manual: save a scenario under Y+2, reload and verify the selector shows Y+2.
- E2E later will validate persist/restore.

### [ ] Step: Helper Unit Tests (Node)
Task definition
- Add `scripts/test_year_context.mjs` to unit-test core computations in isolation.

Contracts (from spec)
- Tests for `contextualizePlayer` across edge cases and `calcCapSummaryForContext` parity with `projectTeamCaps`.

Deliverable
- Node script exists and exits with code 0 when assertions pass.

Verification
- Run `node scripts/test_year_context.mjs` and ensure it finishes without throwing.

### [ ] Step: E2E Tests For Year Context
Task definition
- Add `tests/e2e/year-context.spec.ts` that exercises the selector, header/column labels, roster counts, release modal preview in context, and scenario persistence.

Contracts (from spec)
- Use testids: `year-context-*`, `year-context-label`, `col-cap-label`, header projections stability, etc.

Deliverable
- Deterministic E2E covering Y+0 default and Y+1/Y+2 behavior; projections tab remains semantically unchanged.

Verification
- Run `npm run test:e2e` and ensure all tests (existing + new) pass.

### [ ] Step: Regression & Polish
Task definition
- Run full test suite; tidy console warnings; update `docs/roster_cap_tool/USAGE.md` with a short note on Year Context.

Contracts
- None new; ensure backward-compatible defaults and unchanged behavior under Y+0.

Deliverable
- Clean run of all tests; concise docs note; no regressions in existing features.

Verification
- `npm run test:e2e` passes; quick manual click-through of tabs under Y+0 and Y+1.
