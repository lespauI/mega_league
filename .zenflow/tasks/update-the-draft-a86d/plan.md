# New feature


## Configuration
- **Artifacts Path**: `.zenflow/tasks/{task_id}`
the actual path should be substituted for {@artifacts_path}

---

## Workflow Steps

### [x] Step: Requirements
<!-- chat-id: 4df86cb0-c237-4a9a-8eb4-7d6edc9fbcb3 -->

Your job is to generate a Product Requirements Document based on the feature description,

First, analyze the provided feature definition and determine unclear aspects.  For unclear aspects:
       - Make informed guesses based on context and industry standards
       - Only mark with [NEEDS CLARIFICATION: specific question] if:
         - The choice significantly impacts feature scope or user experience
         - Multiple reasonable interpretations exist with different implications
         - No reasonable default exists
      - Prioritize clarifications by impact: scope > security/privacy > user experience > technical details

Ask up to 5 most priority clarifications to the user. Then, create the document following this template:

```
# Feature Specification: [FEATURE NAME]


## User Stories*


### User Story 1 - [Brief Title]

**Acceptance Scenarios**:

1. **Given** [initial state], **When** [action], **Then** [expected outcome]
2. **Given** [initial state], **When** [action], **Then** [expected outcome]

---

## Requirements*

## Success Criteria*

```

Save the PRD into `{@artifacts_path}/requirements.md`.

### [x] Step: Technical Specification
<!-- chat-id: 08711d50-bc77-41a0-b5e0-ca189fefc4d4 -->

Based on the PRD in `{@artifacts_path}/requirements.md`, create a detailed technical specification to be used by a coding agent to implement the feature. Follow this template:

```
# Technical Specification: [FEATURE]

## Technical Context
Language/Version, primary dependencies, etc

## Technical Implementation Brief

Summarize key technical decisions for implementing the feature. Make sure they take into account the existing code as much as possible.

## Source Code Structure

## Contracts

Define addition or changes in data models, DB schemas, APIs, code interfaces etc

## Delivery Phases

Define several incremental deliverables for the feature. Each should be a minimal viable product testable end-to-end.

## Verification Strategy 

Define how the coding agent can verify each deliverable it creates. Provide instructions for the agent to perform the verification using available tools (lint/test commands, bash commands) and create helper scripts and tools for more complex result verification.
The verification for each deliverable should be executable by a coding agent using built-in capabilities (lint and test commands from the project, bash commands), pre-generated helper scripts or MCP servers. Research and add to the spec:

- MCP servers that should be installed to help the agent with the verification 

- helper scripts that need to be generated in the first phases of the plan to verify complex scenarios that can't be covered by the tests in the project's test framework(s)

- any sample input artifact(s) that are required for verification. Note if these artifacts can be a) generated by the agent; b) discovered by the agent on line; c) must be provided by the user.
```

Save the spec to `{@artifacts_path}/spec.md`.

### [x] Step: Implementation Plan
<!-- chat-id: eb396162-4919-4231-8772-a60c7412407f -->

Based on the technical spec in `{@artifacts_path}/spec.md`, create a detailed task plan and update `{@artifacts_path}/plan.md`. Each task should have task definition, references to contracts to be used/implemented, deliverable definition and verification instructions.

Format each task as 
```
### [ ] Step: <task_name>
Task instructions
```

"Step:" prefix is important, do not omit it!

### [x] Step: Wire Section Intros Support
<!-- chat-id: 2bb29916-cd13-4ef5-bfb3-0890613ddce1 -->
Implement optional, multi-line intro text blocks for key sections.

- Definition:
  - Add `--section-intros <path>` and `--intro-default <str>` flags to `scripts/generate_draft_class_analytics.py`.
  - Implement `read_section_intros(path)` to load JSON mapping for keys: `kpis`, `elites`, `team_quality`, `positions`, `round1`.
  - Render a `<div class="section-intro">...</div>` at the top of KPIs, Elites Spotlight, Team Draft Quality — by Avg OVR, Positions.
- Contracts to use:
  - CLI flags and JSON schema defined in {@artifacts_path}/spec.md (Contracts section).
- Deliverable:
  - Updated `scripts/generate_draft_class_analytics.py` with flags parsing, loader, and HTML injection.
  - CSS: `.section-intro { white-space: pre-wrap; color: #334155; font-size: 13px; margin: 8px 0 12px; }` added to embedded styles.
- Verification:
  - Run: `python3 scripts/generate_draft_class_analytics.py 2026 --players MEGA_players.csv --teams MEGA_teams.csv --section-intros scripts/fixtures/section_intros_example.json`.
  - Open `docs/draft_class_2026.html` and confirm `.section-intro` blocks exist in each targeted section.

### [ ] Step: Extend Rookie Data + Attr/Traits Mapping
<!-- chat-id: 6de8b2bb-e2b0-4307-b461-97101b2a5751 -->
Add data fields and mappings needed for Round 1 player cards.

- Definition:
  - Extend `gather_rookies` to propagate `portraitId` → `portrait_id`, retain `draft_round`, `draft_pick`.
  - Implement helpers: `get_attr_keys_for_pos(pos)`, `get_trait_keys_for_pos(pos)` based on the spec’s position table and key traits list; prefer 8–10 top attributes per position, skip missing fields gracefully.
- Contracts to use:
  - Position attribute and trait mappings from {@artifacts_path}/spec.md (Contracts section).
- Deliverable:
  - Updated `scripts/generate_draft_class_analytics.py` with helpers and enriched rookie dicts.
- Verification:
  - Quick run generation; inspect one rookie of QB/WR/CB in the Round 1 output later to ensure attributes/traits appear and missing keys don’t crash.

### [x] Step: Build and Render Round 1 Recap
<!-- chat-id: f905f5df-9c89-40ac-8899-3d39ca012c92 -->
Append end-of-page recap with every first-round pick in order.

- Definition:
  - Implement `build_round1_entries(players_rows, team_logo_map)` to select rookies with `draft_round == 1`, sort by `draft_pick`, and attach team logo, photo URL (if `portrait_id`), position, and attribute/trait values.
  - Implement `render_round1_recap(entries)` to emit HTML cards: team logo/name, pick number, player name/pos, grade badge, attributes grid, trait badges, player photo.
  - Add `#round1` section to the page and include optional intro using section-intros mapping (`round1` key).
  - Reuse existing grade badge styling (`.grade-on|near|below`) for a simple pick-grade (initially OK to derive from player OVR bands or placeholder label; preserve non-breaking behavior).
- Contracts to use:
  - Photo URL pattern and draft fields from {@artifacts_path}/spec.md; CSS classes defined in Source Code Structure.
- Deliverable:
  - Updated `scripts/generate_draft_class_analytics.py` with new helpers and final section rendering plus minimal card CSS.
- Verification:
  - Run generator and confirm a `Round 1` section exists with N cards (N≥1), sorted by pick, and images render when `portraitId` exists.

### [x] Step: Add Verification Script
<!-- chat-id: 2b72305e-5e46-460f-962e-c4acab184fbe -->
Create HTML validator for Round 1 and intro blocks.

- Definition:
  - Add `scripts/verify_draft_round1_recap.py` that loads the generated HTML and checks:
    - Presence of `id="round1"` section with at least one entry.
    - Round 1 entries sorted by `Pick 1..N`.
    - If any `portraitId` exists for Round 1, validate corresponding `<img src>` matches `https://ratings-images-prod.pulse.ea.com/madden-nfl-26/portraits/\d+\.png`.
    - `.section-intro` blocks exist in KPIs, Elites Spotlight, Team Draft Quality, Positions.
- Contracts to use:
  - Verification conditions specified in {@artifacts_path}/spec.md (Verification Strategy).
- Deliverable:
  - New file `scripts/verify_draft_round1_recap.py`.
- Verification:
  - Run: `python3 scripts/verify_draft_round1_recap.py 2026 --players MEGA_players.csv --teams MEGA_teams.csv --html docs/draft_class_2026.html` and expect zero errors (non-zero exit on failure).

### [x] Step: Smoke Script Update
<!-- chat-id: 295cea33-30d8-4c5c-bf3e-6363d786474b -->
Extend smoke script to include new verification.

- Definition:
  - Update `scripts/smoke_generate_draft_2026.sh` to run generator with section-intros and then run the new verifier.
- Contracts to use:
  - Example invocation in {@artifacts_path}/spec.md (Verification Strategy).
- Deliverable:
  - Updated `scripts/smoke_generate_draft_2026.sh` including:
    - `python3 scripts/generate_draft_class_analytics.py ... --section-intros scripts/fixtures/section_intros_example.json`
    - `python3 scripts/verify_draft_round1_recap.py ...`
- Verification:
  - Execute the smoke script and confirm successful exit and presence of the new section.

### [x] Step: Provide Example Intros Fixture
Add sample JSON for analysts to edit.

- Definition:
  - Create `scripts/fixtures/section_intros_example.json` with placeholder copy for each supported key (`kpis`, `elites`, `team_quality`, `positions`, `round1`).
- Contracts to use:
  - JSON example from {@artifacts_path}/spec.md.
- Deliverable:
  - New file `scripts/fixtures/section_intros_example.json`.
- Verification:
  - Run generator with `--section-intros scripts/fixtures/section_intros_example.json` and check that text appears as expected at the top of target sections.

### [x] Step: add mock draft data
<!-- chat-id: fb0df213-5e20-44da-ae72-d664ed670d8e -->

Git pull draft branch, i add file draft_mock.md
This is analytics before draft, our goal is to add spoiler (wrapped) section to every first round pick "Что говорили анал итики" and add data from this table, about the player, about the team needs and etc
